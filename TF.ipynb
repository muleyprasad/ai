{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YNyQHG7H-XvfFbJmA6ZKAD4OmKOIbhnD",
      "authorship_tag": "ABX9TyMrDEP0O4TJybuaDqcKkriX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/muleyprasad/ai/blob/master/TF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wx3npwKMq3N"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your data from the Excel file\n",
        "data = pd.read_excel('/content/drive/My Drive/Lokmat/merged_data.xlsx')\n",
        "\n",
        "# Combine removal of rows with empty strings in 'city', 'date', 'page', and 'story' columns\n",
        "columns_to_check = ['city', 'date', 'page', 'story']\n",
        "data = data.dropna(subset=columns_to_check)\n",
        "\n",
        "# Combine \"heading\" and \"story\" columns into a single text column\n",
        "data['text'] = data['heading'] + \" \" + data['story']\n",
        "\n",
        "X = data['text'].astype(str)\n",
        "y = data['rating'] - 1 # Labels\n"
      ],
      "metadata": {
        "id": "0olmffhhOkk1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training, validation, and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42) # 0.25 x 0.8 = 0.2"
      ],
      "metadata": {
        "id": "zZ32LoMzPC4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "max_words = 10000  # Set the maximum number of words to consider\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)"
      ],
      "metadata": {
        "id": "-cM7A_5pPKDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "X_test_seq = tokenizer.texts_to_sequences(X_test)"
      ],
      "metadata": {
        "id": "184WPsHgPOaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to ensure they have the same length\n",
        "max_sequence_length = 200 # Set the maximum sequence length\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=max_sequence_length, padding='post')\n",
        "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length, padding='post')"
      ],
      "metadata": {
        "id": "fK0xpVGMPRCd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(input_dim=max_words, output_dim=128, input_length=max_sequence_length),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)), # Use a bidirectional LSTM layer instead of a flatten layer\n",
        "    tf.keras.layers.Dropout(0.2), # Use a dropout layer to prevent overfitting\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(5, activation='softmax') # 5 classes for ratings 1 to 5\n",
        "])"
      ],
      "metadata": {
        "id": "FgQfkwpiPTm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Define an early stopping callback to stop the training when the validation loss stops decreasing\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "KM7HG3qbPW6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model on the training set and validate it on the validation set\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "model.fit(X_train_pad, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_val_pad, y_val), callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqNy_CH9PZH6",
        "outputId": "0cf66227-3d15-4963-cdcf-ceb7cd1abc39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2225/2225 [==============================] - 52s 23ms/step - loss: 1.0232 - accuracy: 0.5707 - val_loss: 1.5100 - val_accuracy: 0.3870\n",
            "Epoch 2/10\n",
            "2225/2225 [==============================] - 52s 23ms/step - loss: 0.9283 - accuracy: 0.6150 - val_loss: 1.6207 - val_accuracy: 0.3783\n",
            "Epoch 3/10\n",
            "2225/2225 [==============================] - 46s 21ms/step - loss: 0.8352 - accuracy: 0.6554 - val_loss: 1.8008 - val_accuracy: 0.3754\n",
            "Epoch 4/10\n",
            "2225/2225 [==============================] - 47s 21ms/step - loss: 0.7495 - accuracy: 0.6930 - val_loss: 2.0750 - val_accuracy: 0.3742\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fbefc3016c0>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_pad, y_test)\n",
        "print(f'Test loss: {loss:.4f}')\n",
        "print(f'Test accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YflQ3B1qRdCd",
        "outputId": "28321ca5-548e-4f85-885d-949a12c45e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1484/1484 [==============================] - 12s 8ms/step - loss: 1.4065 - accuracy: 0.3985\n",
            "Test loss: 1.4065\n",
            "Test accuracy: 0.3985\n"
          ]
        }
      ]
    }
  ]
}